{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqLZ1eJRj5Z6"
      },
      "source": [
        "Importing the Essential Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lm4bbQqMzKjH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sLh6Ga7kInL"
      },
      "source": [
        "Discriminator Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMJtCsA9z3sj"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self,in_features):\n",
        "    super().__init__()\n",
        "    self.disc=nn.Sequential(\n",
        "        nn.Linear(in_features,128),\n",
        "        nn.LeakyReLU(0.01),\n",
        "        nn.Linear(128,1),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.disc(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5e5IQ1SkOsM"
      },
      "source": [
        "Generator Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PGTt7P_THa8"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self,z_dim,img_dim):\n",
        "    super().__init__()\n",
        "    self.gen=nn.Sequential(\n",
        "        nn.Linear(z_dim,256),\n",
        "        nn.LeakyReLU(0.01),\n",
        "        nn.Linear(256,img_dim),\n",
        "        nn.Tanh(),\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.gen(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt9QcPvmkT5y"
      },
      "source": [
        "The device is used to Specify where the computatios should be done either the cpu are the Gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLmTKHX8Wrhe"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters etc.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "lr = 3e-4\n",
        "z_dim = 64\n",
        "image_dim = 28 * 28 * 1  # 784\n",
        "batch_size = 32\n",
        "num_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n"
      ],
      "metadata": {
        "id": "kBEMam0u0bGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fixed_noise.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apd0IZLETiWk",
        "outputId": "ce3f3fbf-0d51-459b-8eef-449c1545ffa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fixed_noise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTmyvuYL0bCs",
        "outputId": "8a492250-7a5a-4ea7-8cce-d75e2c88b029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3534, -1.8301,  0.1081,  ...,  0.6434, -0.2750,  1.0755],\n",
            "        [ 0.8131,  0.8235, -3.0663,  ..., -1.1956, -0.4995,  0.6794],\n",
            "        [-0.5307, -0.2315,  0.6502,  ...,  1.2649,  0.0963,  1.6428],\n",
            "        ...,\n",
            "        [ 0.4858,  0.2851,  2.0896,  ...,  0.0959,  0.1026,  1.6414],\n",
            "        [-1.1844,  0.8338, -0.4473,  ...,  1.8827,  0.2663,  0.3135],\n",
            "        [-1.1871, -0.4008,  1.1875,  ..., -0.0631,  1.0327, -0.2834]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen = Generator(z_dim, image_dim).to(device)\n",
        "\n",
        "print(gen(fixed_noise).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-xxvY6HRj69",
        "outputId": "dcf2239a-08b9-4ba8-c2a8-f0bd1a6d8d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCFrnXRdkzlu"
      },
      "source": [
        "**transforms.ToTensor()**: This converts the image data into a PyTorch tensor. This is a necessary step because PyTorch works with tensors as input data rather than raw image data.\n",
        "**transforms.Normalize((0.1307,), (0.3881,))**: This normalizes the tensor image with mean and standard deviation. The first tuple (0.1307,) represents the mean for each channel, and the second tuple (0.3881,) represents the standard deviation for each channel. These values are often pre-calculated statistics from the dataset you're working with or are commonly used statistics for standard datasets.[link text](https://)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEJHsvSrZBOM"
      },
      "outputs": [],
      "source": [
        "disc = Discriminator(image_dim).to(device)\n",
        "gen = Generator(z_dim, image_dim).to(device)\n",
        "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n",
        "transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3881,)),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14NFqF1Bnp2i"
      },
      "source": [
        "**DataLoader(dataset, batch_size=batch_size, shuffle=True):**\n",
        " This creates a data loader object. It helps in iterating over the dataset in batches during training. Parameters like batch_size determine the number of samples in each batch, and shuffle=True indicates that the data will be shuffled randomly before each epoch to ensure the model doesn't overfit to the order of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr68hiozZGz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120b2e98-90c1-402d-bbf9-1de29ef5d8a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 17762949.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 481957.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1534581.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2396292.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
        "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
        "criterion = nn.BCELoss()\n",
        "writer_fake = SummaryWriter(f\"logs/fake\")\n",
        "writer_real = SummaryWriter(f\"logs/real\")\n",
        "step = 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, (real, _) in enumerate(loader):\n",
        "\n",
        "\n",
        "  noise = torch.randn(batch_size, z_dim).to(device)\n",
        "  print(\"noice shape \",noise.shape)\n",
        "  fake = gen(noise)\n",
        "  print(\"Fake dim\",fake.shape)\n",
        "\n",
        "\n",
        "  real = real.view(-1, 784).to(device)\n",
        "  batch_size = real.shape[0]\n",
        "  print(\"real shape\",real.shape)\n",
        "\n",
        "  disc_real = disc(real).view(-1)\n",
        "  print(disc_real.shape)\n",
        "  disc_fake = disc(fake).view(-1)\n",
        "  print(disc_fake.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKHEB1iYS2Pn",
        "outputId": "e508aa19-f2f4-42ea-9354-c755f6f51bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noice shape  torch.Size([32, 64])\n",
            "Fake dim torch.Size([32, 784])\n",
            "real shape torch.Size([32, 784])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPz4TO0YZlqs",
        "outputId": "40dd83ef-ace5-429d-f7f7-f1be81c76837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0/50] Batch 0/1875                       Loss D: 0.6849, loss G: 0.6674\n",
            "Epoch [1/50] Batch 0/1875                       Loss D: 0.1046, loss G: 2.2234\n",
            "Epoch [2/50] Batch 0/1875                       Loss D: 0.0928, loss G: 2.8732\n",
            "Epoch [3/50] Batch 0/1875                       Loss D: 0.1053, loss G: 2.8545\n",
            "Epoch [4/50] Batch 0/1875                       Loss D: 0.0359, loss G: 3.8849\n",
            "Epoch [5/50] Batch 0/1875                       Loss D: 0.1486, loss G: 3.1829\n",
            "Epoch [6/50] Batch 0/1875                       Loss D: 0.1530, loss G: 4.3162\n",
            "Epoch [7/50] Batch 0/1875                       Loss D: 0.0909, loss G: 4.4837\n",
            "Epoch [8/50] Batch 0/1875                       Loss D: 0.0532, loss G: 4.4174\n",
            "Epoch [9/50] Batch 0/1875                       Loss D: 0.0706, loss G: 4.3341\n",
            "Epoch [10/50] Batch 0/1875                       Loss D: 0.0261, loss G: 4.8784\n",
            "Epoch [11/50] Batch 0/1875                       Loss D: 0.0489, loss G: 4.7054\n",
            "Epoch [12/50] Batch 0/1875                       Loss D: 0.0179, loss G: 4.9170\n",
            "Epoch [13/50] Batch 0/1875                       Loss D: 0.0480, loss G: 4.6379\n",
            "Epoch [14/50] Batch 0/1875                       Loss D: 0.0175, loss G: 4.7781\n",
            "Epoch [15/50] Batch 0/1875                       Loss D: 0.0463, loss G: 4.4349\n",
            "Epoch [16/50] Batch 0/1875                       Loss D: 0.0242, loss G: 5.4509\n",
            "Epoch [17/50] Batch 0/1875                       Loss D: 0.0912, loss G: 5.2470\n",
            "Epoch [18/50] Batch 0/1875                       Loss D: 0.0540, loss G: 5.5408\n",
            "Epoch [19/50] Batch 0/1875                       Loss D: 0.1492, loss G: 5.0372\n",
            "Epoch [20/50] Batch 0/1875                       Loss D: 0.0091, loss G: 5.4396\n",
            "Epoch [21/50] Batch 0/1875                       Loss D: 0.0405, loss G: 5.2063\n",
            "Epoch [22/50] Batch 0/1875                       Loss D: 0.0111, loss G: 5.4580\n",
            "Epoch [23/50] Batch 0/1875                       Loss D: 0.0719, loss G: 5.4883\n",
            "Epoch [24/50] Batch 0/1875                       Loss D: 0.0077, loss G: 5.5374\n",
            "Epoch [25/50] Batch 0/1875                       Loss D: 0.0202, loss G: 5.1817\n",
            "Epoch [26/50] Batch 0/1875                       Loss D: 0.0051, loss G: 5.5384\n",
            "Epoch [27/50] Batch 0/1875                       Loss D: 0.0044, loss G: 5.3647\n",
            "Epoch [28/50] Batch 0/1875                       Loss D: 0.0117, loss G: 5.2907\n",
            "Epoch [29/50] Batch 0/1875                       Loss D: 0.0080, loss G: 5.1660\n",
            "Epoch [30/50] Batch 0/1875                       Loss D: 0.0044, loss G: 5.7229\n",
            "Epoch [31/50] Batch 0/1875                       Loss D: 0.0094, loss G: 5.7229\n",
            "Epoch [32/50] Batch 0/1875                       Loss D: 0.0677, loss G: 6.5814\n",
            "Epoch [33/50] Batch 0/1875                       Loss D: 0.0020, loss G: 6.1563\n",
            "Epoch [34/50] Batch 0/1875                       Loss D: 0.0032, loss G: 6.0886\n",
            "Epoch [35/50] Batch 0/1875                       Loss D: 0.0055, loss G: 5.4393\n",
            "Epoch [36/50] Batch 0/1875                       Loss D: 0.0023, loss G: 6.2161\n",
            "Epoch [37/50] Batch 0/1875                       Loss D: 0.0037, loss G: 6.3639\n",
            "Epoch [38/50] Batch 0/1875                       Loss D: 0.0025, loss G: 6.1181\n",
            "Epoch [39/50] Batch 0/1875                       Loss D: 0.0026, loss G: 5.9698\n",
            "Epoch [40/50] Batch 0/1875                       Loss D: 0.0027, loss G: 6.7045\n",
            "Epoch [41/50] Batch 0/1875                       Loss D: 0.0029, loss G: 6.4505\n",
            "Epoch [42/50] Batch 0/1875                       Loss D: 0.0038, loss G: 5.8737\n",
            "Epoch [43/50] Batch 0/1875                       Loss D: 0.0014, loss G: 6.8914\n",
            "Epoch [44/50] Batch 0/1875                       Loss D: 0.0281, loss G: 6.8028\n",
            "Epoch [45/50] Batch 0/1875                       Loss D: 0.0038, loss G: 6.6426\n",
            "Epoch [46/50] Batch 0/1875                       Loss D: 0.0016, loss G: 6.6471\n",
            "Epoch [47/50] Batch 0/1875                       Loss D: 0.0030, loss G: 6.6529\n",
            "Epoch [48/50] Batch 0/1875                       Loss D: 0.0034, loss G: 6.1883\n",
            "Epoch [49/50] Batch 0/1875                       Loss D: 0.0006, loss G: 7.5396\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (real, _) in enumerate(loader):\n",
        "        real = real.view(-1, 784).to(device)\n",
        "        batch_size = real.shape[0]\n",
        "\n",
        "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
        "        noise = torch.randn(batch_size, z_dim).to(device)\n",
        "        fake = gen(noise)\n",
        "\n",
        "        disc_real = disc(real).view(-1)\n",
        "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
        "\n",
        "        disc_fake = disc(fake).view(-1)\n",
        "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
        "\n",
        "        lossD = (lossD_real + lossD_fake) / 2\n",
        "        disc.zero_grad()\n",
        "        lossD.backward(retain_graph=True)\n",
        "        opt_disc.step()\n",
        "\n",
        "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
        "        # where the second option of maximizing doesn't suffer from\n",
        "        # saturating gradients\n",
        "        output = disc(fake).view(-1)\n",
        "        lossG = criterion(output, torch.ones_like(output))\n",
        "        gen.zero_grad()\n",
        "        lossG.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "        if batch_idx == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
        "                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n",
        "                data = real.reshape(-1, 1, 28, 28)\n",
        "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
        "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
        "\n",
        "                writer_fake.add_image(\n",
        "                    \"Mnist Fake Images\", img_grid_fake, global_step=step\n",
        "                )\n",
        "                writer_real.add_image(\n",
        "                    \"Mnist Real Images\", img_grid_real, global_step=step\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9wQeDWXvZsbl",
        "outputId": "11da926e-9935-499f-8863-5dde152addc5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate random noise\n",
        "new_noise = torch.randn((1, z_dim)).to(device)\n",
        "\n",
        "# Pass noise through the generator\n",
        "with torch.no_grad():\n",
        "    generated_image = gen(new_noise).reshape(1, 1, 28, 28)  # Reshape to match MNIST image dimensions\n",
        "\n",
        "# Convert tensor to numpy array and then to an image\n",
        "generated_image = generated_image.cpu().detach().numpy()  # Move to CPU and detach from gradients\n",
        "generated_image = np.squeeze(generated_image)  # Remove single-dimensional entries from the shape of an array\n",
        "\n",
        "# Display the generated image\n",
        "plt.imshow(generated_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZIbA4Idgg-VX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}